{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usable Data Mask (UDM2) Cloud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this guide, you'll learn about Planet's automatic detection of pixels which are cloudy or otherwise obscured, so that you can make more intelligent choices about whether the data meets your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2018, Planet undertook a project to improve cloud detection, and this guide will focus on the improved metadata that can be used for filtering and the new `ortho_udm2` asset that provides access to detail classification of every pixel. This new information will be available for all `PSScene` items created after 2018-08-01 and for some items before this date (note that a very small number of items created after this date are without the `ortho_udm2` asset).\n",
    "\n",
    "### UDM2.1\n",
    "\n",
    "In November 2023, Planet launched version 2.1 of the Usable Data Mask (UDM2), which deprecates the 'heavy haze' class in favor of a single 'light haze' class. The new version is also substantially more accurate when recognizing clouds, cloud shadows, snow, and haze.\n",
    "\n",
    "Assets from about December 2023 onward, the `heavy_haze` channel will be zeros only. Haze will still be captured via the `light_haze` channel. Note therefore that any queries for assets after this date with `heavy_haze_percent > 0` will not return any results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full specification\n",
    "\n",
    "The full specification for the `ortho_udm2` asset and the related metadata fields can be found in the [UDM2](https://developers.planet.com/docs/api/udm-2/) section of the API documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding clear imagery\n",
    "\n",
    "One of the benefits of accurate and automated cloud detection is that it allows users to filter out images that don't meet a certain quality threshold. Planet's Data API allows users to [search](https://developers.planet.com/docs/apis/data/searches-filtering/) based on the value of the imagery metadata.\n",
    "\n",
    "For example, if you are using the Planet command-line tool, you can search for all four-band PlanetScope scenes that have less than 10% cloud cover in them with the following:\n",
    "\n",
    "    planet data filter --range cloud_percent lt 10 --asset ortho_analytic_4b,ortho_udm2 | planet data search PSScene \n",
    "    \n",
    "Planet's cloud detection algorithm classifies every pixel into one of six different categories, each of which has a corresponding metadata field that reflects the percentage of data that falls into the category.\n",
    "\n",
    "| Class | Metadata field |\n",
    "| --- | --- |\n",
    "| clear | `clear_percent` |\n",
    "| snow | `snow_ice_percent` |\n",
    "| shadow | `shadow_percent` |\n",
    "| light haze | `light_haze_percent` |\n",
    "| heavy haze| `heavy_haze_percent` |\n",
    "| cloud | `cloud_percent` |\n",
    "\n",
    "These can be combined to refine search results even further. An example of searching for imagery that has less than 10% clouds and less than 10% heavy haze:\n",
    "\n",
    "    planet data filter --range cloud_percent lt 10 --range heavy_haze_percent lt 10 --asset ortho_analytic_4b,ortho_udm2 | planet data search PSScene\n",
    "    \n",
    "Every pixel will be classified into only one of the categories above; a pixel may be snowy or obscured by a shadow but it can not be both at the same time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example will show how to do a search for imagery that is at least 90% clear using Planet's Python client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from planet import Auth, Session, DataClient, data_filter\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import rasterio\n",
    "import requests\n",
    "\n",
    "from rasterio.plot import show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if your Planet API Key is not set as an environment variable, you can paste it below\n",
    "API_KEY = os.getenv('PL_API_KEY', 'PASTE_YOUR_KEY_HERE')\n",
    "\n",
    "client = Auth.from_key(API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define filters\n",
    "clear_percent_filter = data_filter.range_filter('clear_percent', 90)\n",
    "asset_filter = data_filter.asset_filter(['basic_analytic_4b'])\n",
    "\n",
    "combined_filter = data_filter.and_filter([clear_percent_filter, asset_filter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are requesting PlanetScope 4 Band imagery\n",
    "item_types = ['PSScene']\n",
    "\n",
    "async with Session() as sess:\n",
    "    cl = DataClient(sess)\n",
    "    request = await cl.create_search(name = 'clear_imagery', search_filter=combined_filter, item_types=item_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(json.dumps(request, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search the Data API\n",
    "async with Session() as sess:\n",
    "    cl = DataClient(sess)\n",
    "    items = cl.run_search(search_id=request['id'])\n",
    "    item_list = [i async for i in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the ID of the most recent 10 images that matched\n",
    "for item in item_list[:10]:\n",
    "    print(item['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `udm2` asset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to metadata for filtering, the `ortho_udm2` asset provides a pixel-by-pixel map that identifies the classification of each pixel.\n",
    "\n",
    "In the example below, cloudy pixels are highlighted in yellow, shadows in red and light haze in blue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Original image | `udm2` overlay |\n",
    "| :--- | :--- |\n",
    "| ![Original image](assets/20190228_172942_0f1a_3B_AnalyticMS.png) |  ![Detected clouds](assets/20190228_172942_0f1a_3B_udm2.png) |\n",
    "| `20190228_172942_0f1a_3B_AnalyticMS.tif` | `20190228_172942_0f1a_3B_udm2.tif` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `udm2` structure is to use a separate band for each classification type. Band 2, for example, indicates that a pixel is snowy when its value is 1, band 3 indicates shadow and so on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following Python will download the data above and then display pixels that fall into a certain classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_types = ['PSScene']\n",
    "item_id = \"20190228_172942_0f1a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the data folder if it doesn't exist\n",
    "data_folder = 'data'\n",
    "if not os.path.isdir(data_folder): os.mkdir(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def download_asset(item_type, item_id, asset_type, destination_folder, overwrite=True):\n",
    "    cl = DataClient(Session())\n",
    "\n",
    "    # Get Asset\n",
    "    asset_desc = await cl.get_asset(item_type_id=item_type, item_id=item_id, asset_type_id=asset_type)\n",
    "\n",
    "    # Activate Asset\n",
    "    await cl.activate_asset(asset=asset_desc)\n",
    "\n",
    "    # Wait for asset to become active\n",
    "    print('Awaiting asset activation...', end=' ')\n",
    "    asset = await cl.wait_asset(asset_desc)\n",
    "\n",
    "    # Download Asset\n",
    "    print('Done. Downloading asset.')\n",
    "    asset_path = await cl.download_asset(asset, directory=destination_folder, overwrite=overwrite)\n",
    "    \n",
    "    return asset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file = await download_asset('PSScene', item_id, 'ortho_analytic_4b', data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udm_file = await download_asset('PSScene', item_id, 'ortho_udm2', data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(udm_file) as src:\n",
    "    shadow_mask = src.read(3).astype(bool)\n",
    "    cloud_mask = src.read(6).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(shadow_mask, title=\"shadow\", cmap=\"binary\")\n",
    "show(cloud_mask, title=\"cloud\", cmap=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = shadow_mask + cloud_mask\n",
    "show(mask, title=\"mask\", cmap=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(img_file) as src:\n",
    "    profile = src.profile\n",
    "    img_data = src.read([3, 2, 1], masked=True) / 10000.0 # apply RGB ordering and scale down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(img_data, title=item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data.mask = mask\n",
    "img_data = img_data.filled(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(img_data, title=\"masked image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image stored in `img_data` now has cloudy pixels masked out and can be saved or used for analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
