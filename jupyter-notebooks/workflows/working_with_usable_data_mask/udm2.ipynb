{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usable Data Mask (UDM2) Visualization and Masking\n",
    "\n",
    "The Usable Data Mask (UDM2) is an iteration upon the Unusable Data Mask (UDM) product. It is available for many products and it contains the UDM as one of its bands. Specifications for the UDM2 are given in the [Imagery Spec Sheet](https://assets.planet.com/docs/Planet_Combined_Imagery_Product_Specs_letter_screen.pdf) and the [UDM2 API documentation](https://developers.planet.com/docs/api/udm-2/).\n",
    "\n",
    "The UDM2 is a multi-band image. The first six bands are boolean bands that encode the absence or presence of different image usability concerns such as haze, clouds, and cloud shadows. The seventh band provides the confidence in the usability assessments as integer values between 0 and 100. The eighth band is the Unusable Data Mask, which is described in the Imagery Spec Sheet referenced above and explored in the [UDM notebook](./udm.ipynb).\n",
    "\n",
    "In this notebook, we demonstrate how to visualize the UDM2 bands and how to convert the UDM2 into two masks: masking all unclear pixels and masking cloud and cloud shadow pixels.\n",
    "\n",
    "### Note on UDM2.1\n",
    "\n",
    "After November 2023, with the launch of UDM2.1, the heavy haze class has been deprecated. A new computer vision model trained at Planet returns more accurate class masks, and includes only a single haze class. For backwards compatibility, `light_haze` will store this haze detection, whereas `heavy_haze` will return zero for all pixels going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies and Set Up Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, OrderedDict\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "from planet import Session, DataClient, Auth\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if your Planet API Key is not set as an environment variable, you can paste it below\n",
    "API_KEY = os.getenv('PL_API_KEY', 'PASTE_YOUR_KEY_HERE')\n",
    "\n",
    "client = Auth.from_key(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Scene\n",
    "\n",
    "The UDM2 asset is available for the `PSScene` item-type. Not all PSScene 4-Band scenes have a UDM2 asset, so here we define the scene and item-type for the UDM2 asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_type = 'PSScene'\n",
    "item_id = '20231103_101837_21_2455'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Metadata\n",
    "\n",
    "Visualize the metadata for the scene `PSScene` item-type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from planet import data_filter\n",
    "\n",
    "sfilter = data_filter.and_filter([\n",
    "    data_filter.permission_filter(),\n",
    "    data_filter.string_in_filter('id', [item_id])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def query():\n",
    "    async with Session() as sess:\n",
    "        cl = sess.client('data')\n",
    "        items = [i async for i in cl.search(['PSScene'], sfilter)]\n",
    "        return items\n",
    "\n",
    "metadata = await query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also search by other fields using other [Search Filters](https://developers.planet.com/docs/apis/data/searches-filtering/), e.g. by date range, geometry, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the data folder if it doesn't exist\n",
    "data_folder = 'data'\n",
    "if not os.path.isdir(data_folder): os.mkdir(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a helper function for activating and downloading image assets\n",
    "async def download_asset(item_type, item_id, asset_type, destination_folder, overwrite=True):\n",
    "    cl = DataClient(Session())\n",
    "\n",
    "    # Get Asset\n",
    "    asset_desc = await cl.get_asset(item_type_id=item_type, item_id=item_id, asset_type_id=asset_type)\n",
    "\n",
    "    # Activate Asset\n",
    "    await cl.activate_asset(asset=asset_desc)\n",
    "\n",
    "    # Wait for asset to become active\n",
    "    print('Awaiting asset activation...', end=' ')\n",
    "    asset = await cl.wait_asset(asset_desc)\n",
    "\n",
    "    # Download Asset\n",
    "    print('Done. Downloading asset.')\n",
    "    asset_path = await cl.download_asset(asset, directory=destination_folder, overwrite=overwrite)\n",
    "    \n",
    "    return asset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_type = 'basic_analytic_4b' # for the orthorectified asset, use ortho_analytic_4b\n",
    "destination_folder = 'data'\n",
    "\n",
    "img_file = await download_asset(item_type, item_id, asset_type, destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the scene filename for processing and make sure the file exists\n",
    "scene_filename = os.path.join('data', item_id + '_1B_AnalyticMS.tif')\n",
    "print(scene_filename)\n",
    "assert os.path.isfile(scene_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions: loading an image\n",
    "NamedBands = namedtuple('NamedBands', 'b, g, r, nir')\n",
    "\n",
    "def load_masked_bands(filename):\n",
    "    \"\"\"Loads a 4-band BGRNir Planet Image file as a list of masked bands.\n",
    "    \n",
    "    The masked bands share the same mask, so editing one band mask will\n",
    "    edit them all.\"\"\"\n",
    "    with rasterio.open(filename) as src:\n",
    "        b, g, r, nir = src.read()\n",
    "        mask = src.read_masks(1) == 0 # 0 value means the pixel is masked\n",
    "    \n",
    "    bands = NamedBands(b=b, g=g, r=r, nir=nir)\n",
    "    return NamedBands(*[np.ma.array(b, mask=mask)\n",
    "                        for b in bands])\n",
    "\n",
    "\n",
    "print(load_masked_bands(scene_filename).b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions: displaying an image\n",
    "def _linear_scale(ndarray, old_min, old_max, new_min, new_max):\n",
    "    \"\"\"Linear scale from old_min to new_min, old_max to new_max.\n",
    "    \n",
    "    Values below min/max are allowed in input and output.\n",
    "    Min/Max values are two data points that are used in the linear scaling.\n",
    "    \"\"\"\n",
    "    #https://en.wikipedia.org/wiki/Normalization_(image_processing)\n",
    "    return (ndarray - old_min)*(new_max - new_min)/(old_max - old_min) + new_min\n",
    "\n",
    "\n",
    "def _mask_to_alpha(bands):\n",
    "    band = np.atleast_3d(bands)[...,0]\n",
    "    alpha = np.zeros_like(band)\n",
    "    alpha[~band.mask] = 1\n",
    "    return alpha\n",
    "\n",
    "\n",
    "def _add_alpha_mask(bands):\n",
    "    return np.dstack([bands, _mask_to_alpha(bands)])\n",
    "\n",
    "\n",
    "def bands_to_display(bands, alpha=True):\n",
    "    \"\"\"Converts a list of bands to a 3-band rgb, normalized array for display.\"\"\"\n",
    "    rgb_bands = np.dstack(bands[:3])\n",
    "\n",
    "    old_min = np.percentile(rgb_bands, 2)\n",
    "    old_max = np.percentile(rgb_bands, 98)\n",
    "    new_min = 0\n",
    "    new_max = 1\n",
    "    scaled = _linear_scale(rgb_bands.astype(np.double),\n",
    "                           old_min, old_max, new_min, new_max)\n",
    "    bands = np.clip(scaled, new_min, new_max)\n",
    "    if alpha is True:\n",
    "        bands = _add_alpha_mask(bands)\n",
    "    return bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "bands = load_masked_bands(scene_filename)\n",
    "plt.imshow(bands_to_display([bands.r, bands.g, bands.b]))\n",
    "\n",
    "plt.title('Scene')\n",
    "ax = plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download UDM2\n",
    "\n",
    "To download the UDM2, we use the planet CLI because it handles activating, waiting for activation, and downloading the file.\n",
    "\n",
    "We will save the UDM2 in the data folder. This folder isn't tracked by git so the downloaded image file will not bloat our git repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udm_file = await download_asset(item_type, item_id, 'ortho_udm2', destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the udm2 filename for processing and make sure the file exists\n",
    "udm2_filename = os.path.join('data', item_id + '_3B_udm2.tif')\n",
    "print(udm2_filename)\n",
    "assert os.path.isfile(udm2_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load UDM2\n",
    "\n",
    "In this section, we implement functionality for loading the UDM2 and identifying the bands. We load the UDM2 used in this notebook and determine the percentage of pixels that are clear of any usability concerns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for loading a UDM2 image and identify bands as class labels\n",
    "def load_udm2(udm2_filename):\n",
    "    '''Load multi-band UDM2 as a 3d array.'''\n",
    "    with rasterio.open(udm2_filename, 'r') as src:\n",
    "        udm2 = src.read()\n",
    "    return udm2\n",
    "\n",
    "\n",
    "udm2_labels = ['clear', 'snow', 'shadow', 'light haze', 'heavy haze', 'cloud',\n",
    "               'confidence', 'unusable pixels']\n",
    "\n",
    "udm2 = load_udm2(udm2_filename)\n",
    "print(udm2.shape)\n",
    "print(udm2_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pixels = np.size(udm2[0,:])\n",
    "num_clear = np.count_nonzero(udm2[0,:])\n",
    "            \n",
    "percent_clear = 100 * (num_pixels - num_clear) / num_pixels\n",
    "print(\"{0:.01f}% of pixels are considered 'clear'\".format(percent_clear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize UDM2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing a Classified Band\n",
    "\n",
    "In this section we develop the capability to visualize a classified band, as UDM2 bands are classified bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classified_band(class_band, class_labels=None,\n",
    "                         cmap='rainbow',\n",
    "                         title='Class Labels', figdim=10):\n",
    "\n",
    "    fig = plt.figure(figsize=(figdim, figdim))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    imshow_class_band(ax, class_band, class_labels=class_labels, cmap=cmap)\n",
    "    ax.set_title(title)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    \n",
    "def imshow_class_band(ax, class_band, class_labels=None, cmap='rainbow'):\n",
    "    \"\"\"Show classified band with colormap normalization and color legend.\n",
    "    Alters ax in place.\n",
    "    \n",
    "    possible cmaps ref:\n",
    "    https://matplotlib.org/examples/color/colormaps_reference.html\n",
    "    \"\"\"\n",
    "    class_norm = _ClassNormalize(class_band)\n",
    "    im = ax.imshow(class_band, cmap=cmap, norm=class_norm)\n",
    "\n",
    "    try:\n",
    "        # add class label legend\n",
    "        # https://stackoverflow.com/questions/25482876\n",
    "        # /how-to-add-legend-to-imshow-in-matplotlib\n",
    "        color_mapping = class_norm.mapping\n",
    "        colors = [im.cmap(color_mapping[k])\n",
    "                  for k in class_labels.keys()]\n",
    "        labels = class_labels.values()\n",
    "\n",
    "        # https://matplotlib.org/users/legend_guide.html\n",
    "        # tag: #creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
    "        patches = [mpatches.Patch(color=c, label=l)\n",
    "                   for c,l in zip(colors, labels)]\n",
    "\n",
    "        ax.legend(handles=patches, bbox_to_anchor=(1, 1),\n",
    "                  loc='upper right', borderaxespad=0.)\n",
    "    except AttributeError:\n",
    "        # class_labels not specified\n",
    "        pass\n",
    "\n",
    "\n",
    "# Inspired by\n",
    "# https://matplotlib.org/users/colormapnorms.html#custom-normalization-two-linear-ranges\n",
    "class _ClassNormalize(colors.Normalize):\n",
    "    \"\"\"Matplotlib colormap normalizer for a classified band.\"\"\"\n",
    "    def __init__(self, arry):\n",
    "        # get unique unmasked values\n",
    "        values = [v for v in np.unique(arry)\n",
    "                  if not isinstance(v, np.ma.core.MaskedConstant)]\n",
    "\n",
    "        # map unique values to points in the range 0-1\n",
    "        if len(values) > 1:\n",
    "            color_ticks = np.array(range(len(values)), dtype=float) / (len(values) - 1)\n",
    "        else:\n",
    "            color_ticks = np.array([0])\n",
    "\n",
    "        self._mapping = dict((v, ct) for v, ct in zip(values, color_ticks))\n",
    "        \n",
    "        # Initialize base Normalize instance\n",
    "        vmin = 0\n",
    "        vmax = 1\n",
    "        clip = False\n",
    "        colors.Normalize.__init__(self, vmin, vmax, clip)\n",
    "    \n",
    "    def __call__(self, arry, clip=None):\n",
    "        '''Create classified representation of arry for display.'''\n",
    "        # round array back to ints for logical comparison\n",
    "        arry = np.around(arry)\n",
    "        new_arry = arry.copy()\n",
    "        for k, v in self._mapping.items():\n",
    "            new_arry[arry==k] = v\n",
    "        return new_arry\n",
    "    \n",
    "    @property\n",
    "    def mapping(self):\n",
    "        '''property required for colors.Normalize classes\n",
    "        \n",
    "        We update the _mapping property in __init__ and __call__ and just\n",
    "        return that property here.\n",
    "        '''\n",
    "        return self._mapping\n",
    "    \n",
    "\n",
    "# test out classified band visualization\n",
    "test_classified_band = np.array(range(9)).reshape((3,3))\n",
    "plot_classified_band(test_classified_band, title='Test Classified Band',\n",
    "                     figdim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize UDM2 Bands\n",
    "\n",
    "The UDM2 product consists of multiple bands. The first six bands are boolean, present/absent. The seventh band is greyscale, and the eighth is the original bit-encoded UDM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_udm2(udm2, figsize=(15,15)):\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=2,\n",
    "                                   sharex=True, sharey=True,\n",
    "                                   figsize=figsize,\n",
    "                            constrained_layout=True)\n",
    "    \n",
    "    bands = [np.squeeze(b) for b in \n",
    "             np.split(udm2, udm2.shape[0], axis=0)]\n",
    "    band_labels = udm2_labels\n",
    "\n",
    "    fig.suptitle('UDM2 Bands', fontsize=20)\n",
    "    bal = zip(bands, axes.flat, udm2_labels)\n",
    "    for i, (band, ax, label) in enumerate(bal):\n",
    "        unique = np.unique(band)\n",
    "    \n",
    "        # it is unwieldy to show a legend for more than 5 values\n",
    "        if len(unique) < 5:\n",
    "            class_labels = OrderedDict((v, v) for v in np.unique(band))\n",
    "        else:\n",
    "            class_labels = None\n",
    "        imshow_class_band(ax, band, class_labels=class_labels, cmap='Greys_r')\n",
    "        ax.set_title(label)\n",
    "        ax.set_axis_off()\n",
    "\n",
    "visualize_udm2(udm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clear band is a combination of all of the other bands. It identifies the snow, clouds, cloud shadows, and light and heavy haze. There appears to be no heavy haze and just a touch of light haze and snow. Really, though, this is a picture of San Francisco, so light haze is possible but snow is unlikely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize UDM2 Unusable Data Mask Band\n",
    "\n",
    "The Unusable Data Mask band of the UDM2 is the original UDM. It is a bit-encoded representation of whether a pixel is usable and, if not, why. Let's check out the usability of the pixels in this image. This section pulls functionality from the [UDM notebook](../udm/udm.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_udm_labels(udm):\n",
    "    '''Get the interpretation of the UDM binary values'''    \n",
    "    def get_label(v):\n",
    "        if v == 0:\n",
    "            label = 'clear'\n",
    "        elif v == 1:\n",
    "            label = 'blackfill'\n",
    "        else:\n",
    "            labels = []\n",
    "            if v & int('10', 2):\n",
    "                labels.append('cloud')\n",
    "            if v & int('11111100', 2):\n",
    "                bands = []\n",
    "                if v & int('100', 2):\n",
    "                    bands.append('Blue')\n",
    "                if v & int('1000', 2):\n",
    "                    bands.append('Green')\n",
    "                if v & int('10000', 2):\n",
    "                    bands.append('Red')\n",
    "                if v & int('100000', 2):\n",
    "                    bands.append('Red-Edge')\n",
    "                if v & int('1000000', 2):\n",
    "                    bands.append('NIR')\n",
    "                if v & int('10000000', 2):\n",
    "                    bands.append('Coastal Blue/Green I/Yellow')\n",
    "                labels.append('missing/suspect {} data'.format(', '.join(bands)))\n",
    "                \n",
    "            if not len(labels):\n",
    "                labels.append('{0:08b}'.format(v))\n",
    "\n",
    "            label = ' + '.join(labels)\n",
    "        return label\n",
    "\n",
    "    return OrderedDict((v, get_label(v)) for v in np.unique(udm))\n",
    "\n",
    "udm2_udm = udm2[-1, ...]\n",
    "print('Labels present in this UDM2 UDM band')\n",
    "get_udm_labels(udm2_udm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def visualize_udm2_unusable(udm2, figsize=(15,15)):\n",
    "    '''Visualize the unusable data mask band of the UDM2 product.'''\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1,\n",
    "                                   sharex=True, sharey=True,\n",
    "                                   figsize=figsize)\n",
    "    band = udm2[-1, :]\n",
    "    label = udm2_labels[-1]\n",
    "\n",
    "    imshow_class_band(ax, band, class_labels=get_udm_labels(band), cmap='rainbow')\n",
    "    ax.set_title(label)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "visualize_udm2_unusable(udm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the pixels within the footprint of the image are usable (purple). Most of those that aren't usable are identified as clouds (teal). Just a few pixels have suspect RGB data, likely due to saturation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert UDM2 to Mask\n",
    "\n",
    "Converting the UDM2 to a binary mask is pretty straightforward. If one is just interested in only the 'clear' pixels, then they can use the first band of the UDM2 (clear band). The same can be said for avoiding 'cloud' pixels, 'haze' pixels, etc. Masking cloud and cloud shadow pixels is a little more complicated, but still pretty simple. Here, we show how to create a mask that masks all unclear pixels and how to create a mask that masks all cloud and cloud shadow pixels.\n",
    "\n",
    "### Mask all unclear pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_class_labels = {0: 'unmasked', 1: 'masked'}\n",
    "mask_cmap = 'viridis' # looks better when just two colors are displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_unclear(udm2_array):\n",
    "    '''Create a mask from the udm2, masking all unclear pixels''' \n",
    "    return udm2_array[0,...] == 0\n",
    "\n",
    "plot_classified_band(mask_unclear(udm2),\n",
    "                     class_labels=mask_class_labels,\n",
    "                     cmap=mask_cmap,\n",
    "                     title='Mask All Unclear Pixels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask cloud and cloud shadow pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_cloud_shadow(udm2_array):\n",
    "    '''Create a mask from the udm2, masking all cloud and cloud shadow pixels'''\n",
    "    shadow_band = udm2_array[2,...]\n",
    "    cloud_band = udm2_array[5,...]\n",
    "    masked_pixels = np.logical_or(shadow_band == 1, cloud_band == 1)\n",
    "    return masked_pixels\n",
    "\n",
    "plot_classified_band(mask_cloud_shadow(udm2),\n",
    "                     class_labels=mask_class_labels,\n",
    "                     cmap=mask_cmap,\n",
    "                     title='Mask All Cloud and Cloud Shadow Pixels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
