{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Footprint: Rasters to Vectors\n",
    "\n",
    "This notebook demonstrates the process of converting an output of the Analytics Feed (building footprint raster) into a vector dataset, using the following steps:\n",
    "\n",
    "1. Obtaining An Analytics Raster\n",
    "2. Downloading Quad Raster\n",
    "3. Visualizing Buildings Image\n",
    "4. Converting Buildings Raster to Vector Features using the following techniques:\n",
    "    * GDAL CLI\n",
    "    * Rasterio (no processing)\n",
    "    * Rasterio (with simplification)\n",
    "    * Rasterio (flexible function, filtering and simplification as example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "from pprint import pprint\n",
    "from planet import Auth\n",
    "from planet import Session, DataClient, OrdersClient\n",
    "import fiona\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio import features as rfeatures\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.plot import show\n",
    "import shapely\n",
    "from shapely.geometry import shape as sshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if your Planet API Key is not set as an environment variable, you can paste it below\n",
    "API_KEY = os.environ.get('PL_API_KEY', 'PASTE_API_KEY_HERE')\n",
    "\n",
    "client = Auth.from_key(API_KEY)\n",
    "\n",
    "# Use our API key as the basic authentication username\n",
    "apiAuth = (API_KEY, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working With Analytic Feed Results\n",
    "\n",
    "**Results** on the Planet Analytics API represent the output or \"detections\" of our machine learning models. Results are created for each Subscription, and each Subscription is derived from a Feed:\n",
    "\n",
    "*Feed → Subscription → Results* \n",
    "\n",
    "> When new Planet imagery is published that intersects a Subscription's AOI and TOI, Planet’s computer vision models process the imagery and the output is added to a \"collection\" (OGC API - Features) of Results associated with a Subscription.\n",
    "\n",
    "\n",
    "#### Feed / Result Types\n",
    "\n",
    "As we've seen, several types of **Feeds** exist, and Results for Feed Subscriptions can be categorized as one of three types: `Object Detection`, `Segmentation`, and `Change Detection`. This notebook covers the `Object Detection` and `Segmentation` feed types, while the next notebook covers `Change Detection` feeds.\n",
    "\n",
    "\n",
    "#### Types of Feeds + Result Output Format\n",
    "\n",
    "| Feed Type | Results Type | Results Format ||\n",
    "| --- | --- | --- | --- |\n",
    "| Vessel Detection | Object Detection | Detection Features (Polygons) |\n",
    "| Building Detection | Segmentation (Classification) | Raster Mask / Basemaps |\n",
    "| Road Detection | Segmentation (Classification) | Raster Mask / Basemaps |\n",
    "| Building Construction Detection | Change Detection | Raster Mask / Basemaps |\n",
    "| Road Construction Detection | Change Detection | Raster Mask / Basemaps |\n",
    "\n",
    "We'll be working with Segmentation Feeds Results in this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Analytics Raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify Building Feed Feature for Download\n",
    "\n",
    "We want to download the most recent feature from the feed for building detection in Sazgin, Turkey.\n",
    "\n",
    "To do this, we need to:\n",
    "1. List All Available Feed IDs\n",
    "2. Identify the Feed ID we will need, corresponding to Building Detection\n",
    "3. List Subscriptions with our selected Feed ID\n",
    "4. Identify the Subscription ID we will need, corresponding to Sazgin, Turkey\n",
    "5. Request the Results Collection corresponding to the Subscription ID we've identified\n",
    "6. Find the most recent Feature from this Feature Collection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup the Request Endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The request should go to the following address: https://api.planet.com/analytics/feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Planet Analytics API base url\n",
    "PAA_BASE_URL = \"https://api.planet.com/analytics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define our endpoints to point to feeds, subscriptions, and collections\n",
    "feeds_endpoint = 'feeds/'\n",
    "subscriptions_endpoint = 'subscriptions/'\n",
    "collections_endpoint = 'collections/'\n",
    "\n",
    "# Construct the URL for the HTTP request \n",
    "# (Planet Analytics API base URL + desired endpoint)\n",
    "feeds_request_url = PAA_BASE_URL + feeds_endpoint\n",
    "subscriptions_request_url = PAA_BASE_URL + subscriptions_endpoint\n",
    "collections_request_url = PAA_BASE_URL + collections_endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List Available Feeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're making a `GET` request, we'll use Requests' `.get` method. Now, let's create our request by passing our request URL and auth variable. Running the next cell should make a call out to the Planet Analytics API.\n",
    "\n",
    "If our request call is **successful** we should get back a response with a [`200 OK`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/200) `HTTP status code`! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the GET request\n",
    "# A succesful request should return a 200 OK status code\n",
    "feeds_response = requests.get(feeds_request_url, auth=apiAuth)\n",
    "\n",
    "print(feeds_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Response Data\n",
    "# Decode the response JSON body to a python dict\n",
    "feeds_response_json = feeds_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Feed IDs\n",
    "for d in feeds_response_json['data']:\n",
    "    print('{} ({}):\\n\\r{}\\n\\r'.format(d['id'], d['created'], d['description']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify Feed ID We'll Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following Feed_ID for Monthly Building Detection from the list above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_id = 'b442c53b-fc72-4bee-bab4-0b7aa318ccd9'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List Subscriptions Containing Our Chosen Feed ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set query parameters for the request\n",
    "# Use the feedID`\n",
    "feed_subscriptions_params = {\"feedID\": feed_id}\n",
    "\n",
    "# Make the request to the api\n",
    "feed_subscriptions_response = requests.get(subscriptions_request_url, params=feed_subscriptions_params, auth=apiAuth).json()\n",
    "\n",
    "# Get the list of subscriptions from the 'data' property of the response\n",
    "subscriptions = feed_subscriptions_response['data']\n",
    "\n",
    "# Print the number of subscriptions found for the given feed\n",
    "print(\"{} subscriptions found for Feed with id:\\n{}\\n\".format(len(subscriptions), feed_id))\n",
    "\n",
    "# Print the subscriptions list\n",
    "print(json.dumps(subscriptions, indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subscription ids\n",
    "for d in subscriptions:\n",
    "    print('{} ({}):\\n\\r{}\\n\\r'.format(d['id'], d['created'], d['title']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify the Subscription ID we will need, corresponding to Sazgin, Turkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building footprints in Sazgin, Turkey\n",
    "subscription_id = '02c4f912-090f-45aa-a18b-ac4a55e4b9ba'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Request the Corresponding Results Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we will request a subscription to look at the subscription details\n",
    "\n",
    "# Construct the URL for the Subscription\n",
    "subscription_url = PAA_BASE_URL + subscriptions_endpoint + subscription_id\n",
    "\n",
    "print(\"Request URL: {}\".format(subscription_url))\n",
    "\n",
    "# Make the GET request for Subscriptions list \n",
    "subscription = requests.get(subscription_url, auth=apiAuth).json()\n",
    "\n",
    "# Get subscription details\n",
    "print(\"{} \\n{}\\nSubscription Id: {}\\n\".format(subscription['title'], subscription['description'], subscription['id']))\n",
    "\n",
    "# Print the subscription object\n",
    "print(json.dumps(subscription, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the URL for the subscription's Results Collection\n",
    "collection_results_url = collections_request_url + subscription['id']\n",
    "\n",
    "print(\"Request URL: {}\".format(collection_results_url))\n",
    "\n",
    "# Get subscription results collection\n",
    "collection_results = requests.get(collection_results_url, auth=apiAuth).json()\n",
    "\n",
    "# Pretty Print response JSON\n",
    "print(json.dumps(collection_results, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request Collection Items\n",
    "# What we got above was the collection itself. We're interested in the items in the collection\n",
    "\n",
    "# Construct the URL for the subscription's Results Collection\n",
    "collection_results_url = collections_request_url + subscription['id'] + '/' + 'items'\n",
    "\n",
    "print(\"Request URL: {}\".format(collection_results_url))\n",
    "\n",
    "# Get subscription results collection\n",
    "collection_items = requests.get(collection_results_url, auth=apiAuth).json()\n",
    "\n",
    "# Pretty Print response JSON\n",
    "print(json.dumps(collection_items, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many features do we have in this collection?\n",
    "\n",
    "features = collection_items['features']\n",
    "print('{} features in collection'.format(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the most recent Feature from this Feature Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort features by acquisition date and take latest feature\n",
    "\n",
    "features.sort(key=lambda k: k['properties']['first_acquired'])\n",
    "feature = features[-1]\n",
    "\n",
    "print (feature)\n",
    "\n",
    "print(feature['properties']['first_acquired'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Quad Raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've identified the feature in the feature collection that we're interested in, we can get this result using a \"GET\" request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading a Result Quad\n",
    "\n",
    "If we want to download the raw quad data, for either the source or output target, we can do so via the Planet Mosaics API. To find the link to the file, we can look at the **Result** item's `links` property . Here's the first result from our Subscription Results collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_links = feature['links']\n",
    "feature_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see the links for both `target-quad` (the result output), and `source-quad` (the source imagery that was used to create the detections). We're interested in downloading the target (result) quad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the URL to target quad\n",
    "target_quad = list(filter(lambda link: link['rel'] == 'target-quad', feature_links))[0]['href']\n",
    "\n",
    "print(\"Target (Result) Quad URL:\\n{}\\n\".format(target_quad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clicking the link in the above cell will download the COG (.tiff) file!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Buildings Image\n",
    "\n",
    "The output of the analytics building detection is a boolean image where building pixels are given a value of True and non-building pixels are given a value of False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set filepaths for target quad (raster), and folder where you'd like our vector files to be downloaded\n",
    "\n",
    "filename = \"TIFF_FILEPATH_HERE\"\n",
    "dest = \"VECTOR_DESTINATION_HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _open(filename, factor=1):\n",
    "    with rasterio.open(filename) as dataset:\n",
    "        height = int(dataset.height / factor)\n",
    "        width = int(dataset.width / factor)\n",
    "        data = dataset.read(\n",
    "            out_shape=(dataset.count, height, width)\n",
    "        )\n",
    "    return data\n",
    "\n",
    "def open_bool(filename, factor=1):\n",
    "    data = _open(filename, factor=factor)\n",
    "    return data[0,:,:]\n",
    "\n",
    "def get_figsize(factor):\n",
    "    return tuple(2 * [int(25/factor)])\n",
    "\n",
    "\n",
    "\n",
    "factor = 1\n",
    "figsize = (15, 15)\n",
    "\n",
    "buildings = open_bool(filename, factor=factor)\n",
    "fig = plt.figure(figsize=figsize)\n",
    "# show(buildings, title=\"footprints\", cmap=\"binary\")\n",
    "show(buildings[2500:3000, 0:500], title=\"footprints\", cmap=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Buildings Raster to Vector Features\n",
    "\n",
    "Here, we examine several different ways to convert our buildings raster into vector features:\n",
    "* GDAL CLI\n",
    "* Rasterio (basic)\n",
    "* Rasterio (simplified)\n",
    "* Rasterio (flexible)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDAL Command-Line Interface (CLI)\n",
    "\n",
    "GDAL provides a python script that can be run via the CLI. It is quite easy to run and fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_name(filename):\n",
    "    # get the default layer output layer name based on the \n",
    "    # output filename. I wish there was a way to specify\n",
    "    # the output layer name but attempts have failed thus far.\n",
    "    return filename.split('/')[-1].split('.')[0]\n",
    "\n",
    "gdal_tmp_output_filename = os.path.join(dest, 'test_gdal_all.shp')\n",
    "gdal_tmp_output_layer_name = get_layer_name(gdal_tmp_output_filename)\n",
    "gdal_output_filename = os.path.join(dest, 'test_gdal.shp')\n",
    "gdal_output_layer_name = get_layer_name(gdal_output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the binary image into polygons\n",
    "# creates polygons for building footprints as well as regions between\n",
    "# and around building footprints\n",
    "!gdal_polygonize.py $filename $gdal_tmp_output_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of features, this includes inside and outside building footprints\n",
    "!ogrinfo -so  $gdal_tmp_output_filename $gdal_tmp_output_layer_name | grep 'Feature Count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of building footprint features\n",
    "# building footprints are associated with image value (DN) of 255\n",
    "!ogrinfo -so $gdal_tmp_output_filename -sql \"SELECT * FROM $gdal_tmp_output_layer_name WHERE DN=255\" \\\n",
    "    | grep 'Feature Count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new shapefile with only building footprints\n",
    "!ogr2ogr -sql \"SELECT * FROM $gdal_tmp_output_layer_name WHERE DN=255\" \\\n",
    "    $gdal_output_filename $gdal_tmp_output_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm the number of building footprint features\n",
    "!ogrinfo -so $gdal_output_filename -sql \"SELECT * FROM $gdal_output_layer_name WHERE DN=255\" \\\n",
    "    | grep 'Feature Count'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rasterio\n",
    "\n",
    "In this section we use rasterio to convert the binary buildings raster into a vector dataset. The vectors are written to disk as a shapefile. The shapefile can be imported into geospatial programs such as QGIS or ArcGIS for visualization and further processing.\n",
    "\n",
    "This is basic conversion to vector shapes. No smoothing to remove pixel edges, or conversion to the building centerlines is performed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildings_as_vectors(filename): \n",
    "    with rasterio.open(filename) as dataset:\n",
    "        buildings = dataset.read(1)\n",
    "        building_mask = buildings == 255 # mask non-building pixels\n",
    "\n",
    "        # transforms buildings\n",
    "        features to image crs\n",
    "        building_shapes = rfeatures.shapes(buildings, mask=building_mask, transform=dataset.transform)\n",
    "        building_geometries = (s for s, _ in building_shapes)\n",
    "        \n",
    "        crs = dataset.crs\n",
    "    return (building_geometries, crs)\n",
    "\n",
    "def save_as_shapefile(output_filename, geometries, crs):\n",
    "    driver='ESRI Shapefile'\n",
    "    schema = {'geometry': 'Polygon', 'properties': []}\n",
    "    with fiona.open(output_filename, mode='w', driver=driver, schema=schema, crs=crs) as c:\n",
    "        count = 0\n",
    "        for g in geometries:\n",
    "            count += 1;\n",
    "            c.write({'geometry': g, 'properties': {}})\n",
    "        print('wrote {} geometries to {}'.format(count, output_filename))\n",
    "\n",
    "        \n",
    "building_geometries, crs = buildings_as_vectors(filename)\n",
    "output_filename = os.path.join(dest, 'test_rasterio.shp')\n",
    "save_as_shapefile(output_filename, building_geometries, crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rasterio - Simplifying\n",
    "\n",
    "In this section, we use `shapely` to simplify the building footprints so we don't have a million pixel edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildings_as_vectors_with_simplification(filename): \n",
    "    with rasterio.open(filename) as dataset:\n",
    "        buildings = dataset.read(1)\n",
    "        building_mask = buildings == 255 # mask non-building pixels\n",
    "\n",
    "        # we skip transform on vectorization so we can perform filtering in pixel space\n",
    "        building_shapes = rfeatures.shapes(buildings, mask=building_mask)\n",
    "        building_geometries = (s for s, _ in building_shapes)\n",
    "        geo_shapes = (sshape(g) for g in building_geometries)\n",
    "    \n",
    "        # simplify so we don't have a million pixel edge points\n",
    "        # value of 1 (in units of pixels) determined by visual comparison to non-simplified\n",
    "        tolerance = 1\n",
    "        geo_shapes = (g.simplify(tolerance, preserve_topology=False)\n",
    "                      for g in geo_shapes)\n",
    "\n",
    "        # apply image transform    \n",
    "        # rasterio transform: (a, b, c, d, e, f, 0, 0, 1), c and f are offsets\n",
    "        # shapely: a b d e c/xoff f/yoff\n",
    "        d = dataset.transform\n",
    "        shapely_transform = [d[0], d[1], d[3], d[4], d[2], d[5]]\n",
    "        proj_shapes = (shapely.affinity.affine_transform(g, shapely_transform)\n",
    "                       for g in geo_shapes)\n",
    "        \n",
    "        building_geometries = (shapely.geometry.mapping(s) for s in proj_shapes)\n",
    "        \n",
    "        crs = dataset.crs\n",
    "    return (building_geometries, crs)\n",
    "\n",
    "building_geometries_simp, crs = buildings_as_vectors_with_simplification(filename)\n",
    "output_filename = os.path.join(dest, 'test_rasterio_simp.shp')\n",
    "save_as_shapefile(output_filename, building_geometries_simp, crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix - Extending the Calculation with Rasterio\n",
    "\n",
    "In this section we get a little bit fancy and set up the rasterio vectorization function so that it can take any calculation function, as long as that function has a generator of `rasterio.shape` as input and a generator of `rasterio.shape` as output. We will use this to filter and simplify building footprint shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildings_as_vectors_proc(filename, proc_fcn): \n",
    "    with rasterio.open(filename) as dataset:\n",
    "        buildings = dataset.read(1)\n",
    "        building_mask = buildings == 255 # mask non-building pixels\n",
    "\n",
    "        # we skip transform on vectorization so we can perform filtering in pixel space\n",
    "        building_shapes = rfeatures.shapes(buildings, mask=building_mask)\n",
    "        building_geometries = (s for s, _ in building_shapes)\n",
    "        geo_shapes = (sshape(g) for g in building_geometries)\n",
    "        \n",
    "        # apply arbitrary processing function\n",
    "        geo_shapes = proc_fcn(geo_shapes)\n",
    "\n",
    "        # apply image transform    \n",
    "        # rasterio transform: (a, b, c, d, e, f, 0, 0, 1), c and f are offsets\n",
    "        # shapely: a b d e c/xoff f/yoff\n",
    "        d = dataset.transform\n",
    "        shapely_transform = [d[0], d[1], d[3], d[4], d[2], d[5]]\n",
    "        proj_shapes = (shapely.affinity.affine_transform(g, shapely_transform)\n",
    "                       for g in geo_shapes)\n",
    "        \n",
    "        building_geometries = (shapely.geometry.mapping(s) for s in proj_shapes)\n",
    "        \n",
    "        crs = dataset.crs\n",
    "    return (building_geometries, crs)\n",
    "\n",
    "def filter_and_simplify_footprints(footprints):\n",
    "    # filter to shapes consisting of 6 or more pixels\n",
    "    min_pixel_size = 6\n",
    "    geo_shapes = (s for s in footprints if s.area >= min_pixel_size)\n",
    "        \n",
    "    # simplify so we don't have a million pixel edge points\n",
    "    # value of 1 (in units of pixels) determined by visual comparison to non-simplified\n",
    "    tolerance = 1\n",
    "    geo_shapes = (s.simplify(tolerance, preserve_topology=False)\n",
    "                  for s in geo_shapes)\n",
    "    return geo_shapes\n",
    "\n",
    "building_geometries_simp, crs = buildings_as_vectors_proc(filename, filter_and_simplify_footprints)\n",
    "output_filename = os.path.join(dest, 'test_rasterio_proc.shp')\n",
    "save_as_shapefile(output_filename, building_geometries_simp, crs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
