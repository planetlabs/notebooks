{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b03c486e",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github//planetlabs/notebooks/blob/master/jupyter-notebooks/workflows/introduction_to_analysis_apis/image_metadata_headers_pip.ipynb)\n",
    "\n",
    "\n",
    "# Lookup Scene Traceability Information for ARPS data in the Planet Insights Platform\n",
    "\n",
    "This notebook covers how to download image metadata header information from the Planet Insights Platform. \n",
    "\n",
    "To demonstrate this, we will use the [Statistical API](https://docs.planet.com/develop/apis/statistical/) to retrieve index values from the `scene_mask` band, and the [BYOC API](https://docs.planet.com/develop/apis/byoc/) to retrieve the ARPS QA header, which can be used to map the scene index values to scene ids, and subsequently derive the actual collection time of any given pixel.\n",
    "\n",
    "The BYOC API can only be used with collections **you own**, not sandbox data or other collections shared with you, so you must have created an ARPS collection in order to utilize this notebook.\n",
    "\n",
    "For an introduction to the Subscriptions API, which can be used to obtain ARPS data, refer to the [Subscriptions API - Data Collection Delivery](https://github.com/planetlabs/notebooks/blob/master/jupyter-notebooks/api_guides/subscriptions_api/subscriptions_to_data_collection.ipynb) notebook.\n",
    "\n",
    "For an introduction to ARPS data, refer to the [Intro to ARPS data in Planet Insights Platform](https://github.com/planetlabs/notebooks/blob/master/jupyter-notebooks/use_cases/calculate_water_extent_analysis_ready_planetscope/calculate_water_extent_analysis_ready_planetscope.ipynb) notebook.\n",
    "\n",
    "For an introduction to the Statistical API, refer to the [First Steps in accessing Satellite Imagery with Sentinel Hub APIs](https://github.com/planetlabs/notebooks/blob/master/jupyter-notebooks/workflows/introduction_to_analysis_apis/introduction_to_analysis_apis.ipynb) notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371e9f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.io import MemoryFile\n",
    "import requests\n",
    "\n",
    "from sentinelhub import (\n",
    "    CRS,\n",
    "    DataCollection,\n",
    "    SentinelHubStatistical,\n",
    "    SentinelHubCatalog,\n",
    "    SentinelHubBYOC,\n",
    "    SentinelHubSession,\n",
    "    BBox,\n",
    "    bbox_to_dimensions,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb410fb9",
   "metadata": {},
   "source": [
    "## ARPS Data Structure\n",
    "\n",
    "ARPS Tiles are constructed from a composite of many different PlanetScope Scenes. In the example below, a total of 10 PS ortho scenes from three separate strips were used to construct the tile image. \n",
    "\n",
    "![Scene Traceability](arps_scene_traceability.webp)\n",
    "\n",
    "Information on what pixels came from what scenes is stored in the ARPS QA dataset. Each footprint is associated with a unique integer value that is linked to a scene identifier (`{item-type}/{scene-id}`) embedded as metadata in the QA geotiff.\n",
    "\n",
    "For more information on ARPS, refer to the [ARPS Technical Specification](https://docs.planet.com/data/imagery/arps/techspec/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127031a4",
   "metadata": {},
   "source": [
    "## Credentials\n",
    "\n",
    "The Sentinel Hub Python SDK requires a `client_id` and a `client_secret`. To obtain your `client_id` & `client_secret`, you need to navigate to your [account manager](insights.planet.com/account/), and in the **User Settings**, create a new OAuth client. More detailed instructions can be found in our [authentication documentation](https://docs.planet.com/develop/authentication/).\n",
    "\n",
    "Once you have your `client_id` & `client_secret`, it is recommended to configure a new profile in your Sentinel Hub Python package. Instructions on how to configure your Sentinel Hub Python package can be found [in the documentation](https://sentinelhub-py.readthedocs.io/en/latest/configure.html). This is useful as changes to the config class in your notebook are usually only temporary and by saving the configuration to your profile, you don't have to generate new credentials or overwrite the default profile every time you run a new Jupyter Notebook.\n",
    "\n",
    "The following cell checks for an existing default configuration. If none is found, you will be prompted for your credentials, which you can then optionally save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6b1ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentinelhub import SHConfig\n",
    "\n",
    "# Authenticate with the Sentinel Hub Python SDK; See docs: https://sentinelhub-py.readthedocs.io/en/latest/configure.html and https://docs.planet.com/develop/authentication\n",
    "# If no default configuration detected, enter a client ID and secret to authenticate. These can be obtained by creating an OAuth client here: https://insights.planet.com/account\n",
    "config = SHConfig()\n",
    "if not config.sh_client_id or not config.sh_client_secret:\n",
    "    from getpass import getpass\n",
    "    print('No credentials found, please provide the OAuth client ID and secret.')\n",
    "    config.sh_client_id = getpass('Client ID: ')\n",
    "    config.sh_client_secret = getpass('Client Secret: ')\n",
    "    ## Uncomment the following lines to save your credentials to a configuration\n",
    "    # config.save() \n",
    "    # print(f'Credentials saved to {SHConfig.get_config_location()}')\n",
    "else:\n",
    "    print(f'Using credentials stored here: {SHConfig.get_config_location()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3e247d",
   "metadata": {},
   "source": [
    "## Collection Configuration\n",
    "\n",
    "Use of the BYOC API requires a collection you own. Update this section with details coorresponding to one of your ARPS collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426611d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape at 3 m resolution: (497, 739) pixels\n"
     ]
    }
   ],
   "source": [
    "# This is the collection ID for your ARPS collection\n",
    "collection_id = \"YOUR-COLLECTION-ID-HERE\"\n",
    "data_collection = DataCollection.define_byoc(collection_id)\n",
    "\n",
    "# Enter a BBOX for your AOI\n",
    "sample_aoi = (-122.44, 37.75, -122.39, 37.79)\n",
    "\n",
    "start_date = \"2023-11-01T00:00:00Z\"\n",
    "end_date = \"2023-12-01T00:00:00Z\"\n",
    "\n",
    "#Resolution of ARPS\n",
    "resolution = 3\n",
    "sample_bbox = BBox(bbox=sample_aoi, crs=CRS.WGS84)\n",
    "sample_size = bbox_to_dimensions(sample_bbox, resolution=resolution)\n",
    "\n",
    "print(f\"Image shape at {resolution} m resolution: {sample_size} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e4f9a5",
   "metadata": {},
   "source": [
    "## Extract Timeseries\n",
    "\n",
    "This example evalscript calculates NDWI from ARPS, similar to the example in the [Intro to ARPS data in Planet Insights Platform](https://github.com/planetlabs/notebooks/blob/master/jupyter-notebooks/use_cases/calculate_water_extent_analysis_ready_planetscope/calculate_water_extent_analysis_ready_planetscope.ipynb) notebook.\n",
    "\n",
    "The scene_mask band has been added as a separate output. Since this is a discrete value, the default `mean` statistic won't be very useful.\n",
    "\n",
    "To account for this, we can add a 50th percentile (median) calculation when making the Statistical API request to find the most common pixel value, corresponding to the scene which covers the most area of the AOI, and use that index to look up the scene id from the metadata. \n",
    "\n",
    "**Note**: This approach works best with relatively small AOIs - less than the size of a typical PlanetScope scene.\n",
    "For a complete listing of all scene indexes within the AOI, you could instead use a [histogram](https://docs.planet.com/develop/apis/statistical/#histogram) covering each value in the [valid range of the pixel traceability band](https://docs.planet.com/data/imagery/arps/techspec/#32-quality-assurance-product-arps-qa), e.g. `\"bins\": list(range(600))` - the `lowEdge` of each nonzero bin will correspond to a scene index found within the AOI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e43c61ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndwi_time_eval = \"\"\"\n",
    "//VERSION=3\n",
    "\n",
    "function setup() {\n",
    "    return {\n",
    "        input: [\n",
    "            {\n",
    "                bands: [\n",
    "                    \"green\",\n",
    "                    \"nir\",\n",
    "                    \"cloud_mask\",\n",
    "                    \"scene_mask\",\n",
    "                    \"dataMask\"\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        output: [\n",
    "            {\n",
    "                id: \"default\",\n",
    "                bands: 1,\n",
    "                sampleType: \"FLOAT32\"\n",
    "            },\n",
    "            {\n",
    "                id: \"scenes\",\n",
    "                bands: 1,\n",
    "                sampleType: \"INT16\"\n",
    "            },\n",
    "            {\n",
    "                id: \"dataMask\",\n",
    "                bands: 1\n",
    "            }\n",
    "        ]\n",
    "    };\n",
    "}\n",
    "\n",
    "function evaluatePixel(sample) {\n",
    "\n",
    "    var noCloudMask = 0\n",
    "    if (sample.cloud_mask==1){\n",
    "        noCloudMask = 1\n",
    "    }\n",
    "    const clear = sample.dataMask * noCloudMask;\n",
    "    var ndwi = (sample.green - sample.nir ) / (sample.green  + sample.nir );\n",
    "\n",
    "    return {\n",
    "        default: [ndwi],\n",
    "        scenes: [sample.scene_mask],\n",
    "        dataMask: [clear]\n",
    "    };\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "245f0090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(collection, eval, interval):\n",
    "    # Stat API calc that calculates NDWI within a date range and the AOI for all available imagery\n",
    "    request = SentinelHubStatistical(\n",
    "        aggregation=SentinelHubStatistical.aggregation(\n",
    "            evalscript=eval,\n",
    "            time_interval=interval,\n",
    "            aggregation_interval=\"P1D\",\n",
    "            size=sample_size,\n",
    "        ), # Percentiles calculation to find the median scene index\n",
    "        calculations={\n",
    "            \"scenes\": {\n",
    "                \"statistics\": {\n",
    "                    \"B0\": {\n",
    "                        \"percentiles\": {\n",
    "                            \"k\": [50],\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        input_data=[SentinelHubStatistical.input_data(collection, maxcc=1)],\n",
    "        bbox=sample_bbox,\n",
    "        config=config,\n",
    "    )\n",
    "    return request.get_data()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b62adf5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'interval': {'from': '2023-11-02T00:00:00Z', 'to': '2023-11-03T00:00:00Z'},\n",
       " 'outputs': {'default': {'bands': {'B0': {'stats': {'min': -0.7755434513092041,\n",
       "      'max': 0.6197183132171631,\n",
       "      'mean': -0.30580023709867454,\n",
       "      'stDev': 0.3505539523621675,\n",
       "      'sampleCount': 367283,\n",
       "      'noDataCount': 228294}}}},\n",
       "  'scenes': {'bands': {'B0': {'stats': {'min': 10.0,\n",
       "      'max': 233.0,\n",
       "      'mean': 208.31724093273664,\n",
       "      'stDev': 69.96439577976244,\n",
       "      'sampleCount': 367283,\n",
       "      'noDataCount': 228294,\n",
       "      'percentiles': {'50.0': 233.0}}}}}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result =  get_stats(data_collection, ndwi_time_eval, (start_date, end_date))\n",
    "# Sample the first result. Note the 50th percentile value\n",
    "result['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f916ec5",
   "metadata": {},
   "source": [
    "## Metadata Lookup\n",
    "\n",
    "### Locating ARPS Tiles with the Catalog API\n",
    "\n",
    "The [Catalog API](https://docs.planet.com/develop/apis/catalog/) can be used to find the ID of each ARPS record in your data collection. This ID is required to download the metadata from the BYOC API later.\n",
    "\n",
    "**Note**: If your AOI spans multiple ARPS tiles, catalog_search will return more than one result.\n",
    "This edge case is not accounted for in this notebook, but you could handle it by discarding the tile that overlaps your BBOX the least, or by splitting your BBOX according to the ARPS tile boundaries, as retrieved from the Catalog API, and making seperate Statistical APIs for each sub-AOI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22c01e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def catalog_search(sh_config: SHConfig, collection: DataCollection, bbox: BBox, start_time: str, end_time: str):\n",
    "    \"\"\"\n",
    "    Simple wrapper around SentinelHubCatalog.search, with more basic options\n",
    "\n",
    "    :param sh_config: SHConfig object with client credentials\n",
    "    :param collection: SentinelHub Collection\n",
    "    :param bbox: Bounding Box\n",
    "    :param start_time: ISO time string\n",
    "    :param end_time: ISO time string\n",
    "    :return: Iterator of search results\n",
    "    \"\"\"\n",
    "\n",
    "    catalog = SentinelHubCatalog(config=sh_config)\n",
    "\n",
    "    return catalog.search(\n",
    "        collection,\n",
    "        bbox=bbox,\n",
    "        time=(start_time, end_time)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db35fb92",
   "metadata": {},
   "source": [
    "Since in this example our BBOX is covered by a single tile, we only expect a single response from the Catalog API, and can use `next()` to get the first value returned by the iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53c6eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_iterator = catalog_search(config, data_collection, sample_bbox, result['data'][0]['interval']['from'], result['data'][0]['interval']['to'])\n",
    "first_tile = next(search_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922e2db9",
   "metadata": {},
   "source": [
    "### Extracting ARPS Metadata with the BYOC API\n",
    "\n",
    "The BYOC API includes a [download endpoint](https://docs.planet.com/develop/apis/byoc/reference/#tag/byoc_tile/operation/getByocTileFile) for downloading files directly.\n",
    "\n",
    "For this use case, we only need the header data of the QA asset, so we can do a range read to download just what we need.\n",
    "The [BYOC Tile Info](https://docs.planet.com/develop/apis/byoc/reference/#tag/byoc_tile/operation/getByocCollectionTileById) response lists each asset for a tile, and the size of the header for that asset, so that we know how much of the file we need to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "489a10db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analysis_ready_ps_qa': {'headerSize': 3521,\n",
       "  'etag': '\"9e4f9cbf89e7a024999cfb1af20cf52b\"'},\n",
       " 'analysis_ready_ps_sr': {'headerSize': 3433,\n",
       "  'etag': '\"9a33f9fd8defffc0e312a9efdc22f352-23\"'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byoc = SentinelHubBYOC(config=config)\n",
    "tile_info = byoc.get_tile(data_collection, first_tile[\"id\"])\n",
    "tile_info[\"additionalData\"][\"filesMetadata\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbda2555",
   "metadata": {},
   "source": [
    "The header will be downloaded as binary data, so we can use `rasterio` to extract the tags in a human-readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67818e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arps_metadata(sh_config: SHConfig, collection: DataCollection, item_id: str) -> dict:\n",
    "    \"\"\"\n",
    "    Use the BYOC to extract the scene mask mapping metadata from an ARPS QA tile\n",
    "    Note: Consumes (a small amount of) PUs\n",
    "\n",
    "    :param sh_config: SH Configuration and credentials\n",
    "    :param collection: SH Collection\n",
    "    :param item_id: Catalog id of the ARPS tile, e.g. from a Catalog API search.\n",
    "    :return: A dict containing the tags from the COG header of the matching ARPS tile\n",
    "    \"\"\"\n",
    "\n",
    "    byoc = SentinelHubBYOC(config=sh_config)\n",
    "\n",
    "    # Use the BYOC API to extract the file name and header size\n",
    "    tile_info = byoc.get_tile(collection, item_id)\n",
    "    target_file = \"analysis_ready_ps_qa\"\n",
    "    file_name = tile_info[\"path\"].split(\"/\")[-1].replace(\"(BAND)\", target_file)\n",
    "    source_len = tile_info[\"additionalData\"][\"filesMetadata\"][target_file][\"headerSize\"]\n",
    "\n",
    "    download_url = f\"https://services.sentinel-hub.com/api/v1/byoc/collections/{collection.collection_id}/tiles/{item_id}/files/{file_name}\"\n",
    "\n",
    "    # Do a range-read of just the header size to get only the metadata\n",
    "    session = SentinelHubSession(config=sh_config)\n",
    "    headers = {\"Range\": f\"bytes=0-{source_len - 1}\",\n",
    "               \"Authorization\": f\"Bearer {session.token['access_token']}\"}\n",
    "    response = requests.get(download_url, headers=headers, stream=True)\n",
    "\n",
    "    bytes = response.content\n",
    "\n",
    "    # Use rasterio to parse the tags from the header\n",
    "    with MemoryFile(bytes) as memfile:\n",
    "        with memfile.open() as dataset:\n",
    "            tags = dataset.tags()\n",
    "\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3049ff64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CREATED': '2024-11-08T17:03:40Z',\n",
       " 'PERCENTAGE_CLEAR': '24.97',\n",
       " 'PIPELINE_VERSION': '1.0.0',\n",
       " 'PS_SCENE_IDS[LAYER_2_VALUE]': 'PSScene/20231102_190001_45_2495[10]\\nPSScene/20231102_190003_53_2495[233]\\nNone[29]',\n",
       " 'RUN_TYPE': 'backfill',\n",
       " 'SCENE_IDS[LAYER_2_VALUE]': 'PSScene/20231102_190001_45_2495[10]\\nPSScene/20231102_190003_53_2495[233]\\nNone[29]',\n",
       " 'SCENE_SOLAR_AZIMUTH[LAYER_2_VALUE]': '165.3[10]\\n165.2[233]\\nNone[29]',\n",
       " 'SCENE_SOLAR_ELEVATION[LAYER_2_VALUE]': '25.6[10]\\n25.7[233]\\nNone[29]',\n",
       " 'AREA_OR_POINT': 'Area'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = get_arps_metadata(config, data_collection, first_tile[\"id\"])\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1545bc12",
   "metadata": {},
   "source": [
    "## Parsing ARPS Metadata and extracting Collection Time\n",
    "\n",
    "Now that we've extracted the QA Metadata header, we can use this information to find out what scene(s) contributed to the data in our BBOX.\n",
    "First, we can parse the scene mask record (`SCENE_IDS[LAYER_2_VALUE]`) to allow mapping of the pixel traceability index to scene id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af912d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_scene_mask(scene_mask: str) -> dict:\n",
    "    \"\"\"\n",
    "    Convert the raw SCENE_IDS[LAYER_2_VALUE] metadata value to a map of LAYER_2_VALUE: Scene_ID\n",
    "    :param scene_mask:\n",
    "    :return: A mapping of the pixel values from the scene_mask layer to the corresponding Scene IDs\n",
    "    \"\"\"\n",
    "    entries = scene_mask.split('\\n')\n",
    "    scene_map = {}\n",
    "    for entry in entries:\n",
    "        scene, idx = entry.split(\"[\")\n",
    "\n",
    "        scene = scene.replace(\"PSScene/\", \"\")\n",
    "\n",
    "        idx = idx.replace(\"]\", \"\")\n",
    "\n",
    "        scene_map[idx] = scene\n",
    "\n",
    "    return scene_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709ff093",
   "metadata": {},
   "source": [
    "With our previously calculated index value, we can use this mapping to find the id of the scene that contributes most to the data in our bounding box:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bc3d26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20231102_190003_53_2495'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_map = parse_scene_mask(metadata['SCENE_IDS[LAYER_2_VALUE]'])\n",
    "# Retrieve the median scene index over our AOI, which we calculated earlier\n",
    "scene_index = str(int(result['data'][0]['outputs']['scenes']['bands']['B0']['stats']['percentiles']['50.0']))\n",
    "scene_id = scene_map[scene_index]\n",
    "scene_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde93efc",
   "metadata": {},
   "source": [
    "## Collection time\n",
    "\n",
    "We can use the scene id to calculate a more precise collection time for our BBOX\n",
    "\n",
    "PlanetScope Scene IDs have a fixed structure, which encodes a [variety of useful information](https://docs.planet.com/data/imagery/planetscope/#product-naming).\n",
    "For this use case, we are just interested in the first 15 characters of the id, which encode the acquisition date (YYYYMMDD) and acquisition time (HHMMSS) in UTC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f283d968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime_from_scene_id(scene_id: str) -> datetime:\n",
    "    \"\"\"\n",
    "    Convert a PSScene Id to the corresponding acquisition time (in UTC)\n",
    "    :param scene_id:\n",
    "    :return: Acquisition time\n",
    "    \"\"\"\n",
    "    scene_tokens = scene_id.split(\"_\")\n",
    "    ymd = scene_tokens[0]\n",
    "    hms = scene_tokens[1]\n",
    "\n",
    "    capture_date = datetime(year=int(ymd[0:4]), month=int(ymd[4:6]), day=int(ymd[6:]), hour=int(hms[0:2]), minute=int(hms[2:4]), second=int(hms[4:]))\n",
    "\n",
    "    return capture_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a050596e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-11-02 19:00:03'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(datetime_from_scene_id(scene_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3e22d3",
   "metadata": {},
   "source": [
    "# Aggregate results\n",
    "\n",
    "Bringing everything together, we can update our statistical results with accurate collection times.\n",
    "Some days won't have an observation, meaning the Statistical API result will be NaN, so there is some filtering necessary to exclude such values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e996fcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN result for 2023-11-04T00:00:00Z, skipping...\n",
      "No matching scene for 2023-11-13T00:00:00Z, index 202. Found 1 matching tile(s)\n",
      "NaN result for 2023-11-19T00:00:00Z, skipping...\n",
      "NaN result for 2023-11-21T00:00:00Z, skipping...\n",
      "No matching scene for 2023-11-24T00:00:00Z, index 28. Found 1 matching tile(s)\n",
      "No matching scene for 2023-11-25T00:00:00Z, index 202. Found 1 matching tile(s)\n",
      "NaN result for 2023-11-26T00:00:00Z, skipping...\n"
     ]
    }
   ],
   "source": [
    "values = []\n",
    "\n",
    "for r in result['data']:\n",
    "    ndwi = r[\"outputs\"]['default']['bands']['B0']['stats']['mean']\n",
    "    tile_date_from = r['interval']['from']\n",
    "    tile_date_to = tile_date_from[0:10] + 'T23:59:59Z'\n",
    "    if ndwi == \"NaN\":\n",
    "        print(f\"NaN result for {tile_date_from}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    scene_index = str(int(r['outputs']['scenes']['bands']['B0']['stats']['percentiles']['50.0']))    \n",
    "    tile_info = list(catalog_search(config, data_collection, sample_bbox, tile_date_from, tile_date_to))\n",
    "    tile_id = tile_info[0][\"id\"]\n",
    "    tile_metadata = get_arps_metadata(config, data_collection, tile_id)\n",
    "    try:\n",
    "        scene_id = parse_scene_mask(tile_metadata['SCENE_IDS[LAYER_2_VALUE]'])[scene_index]\n",
    "        scene_date = datetime_from_scene_id(scene_id)\n",
    "\n",
    "        values.append({\"date\": scene_date, \"ndwi\": ndwi})\n",
    "    except KeyError as e:\n",
    "        print(f\"No matching scene for {tile_date_from}, index {scene_index}. Found {len(tile_info)} matching tile(s)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59859b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ndwi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-02 19:00:03</td>\n",
       "      <td>-0.305800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-07 18:21:45</td>\n",
       "      <td>-0.378623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-08 19:05:05</td>\n",
       "      <td>0.026967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-16 19:21:41</td>\n",
       "      <td>-0.202325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-17 19:01:57</td>\n",
       "      <td>-0.323913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-11-18 19:02:03</td>\n",
       "      <td>-0.357332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-11-22 19:06:27</td>\n",
       "      <td>-0.189824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-11-23 19:22:30</td>\n",
       "      <td>-0.321991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date      ndwi\n",
       "0 2023-11-02 19:00:03 -0.305800\n",
       "1 2023-11-07 18:21:45 -0.378623\n",
       "2 2023-11-08 19:05:05  0.026967\n",
       "3 2023-11-16 19:21:41 -0.202325\n",
       "4 2023-11-17 19:01:57 -0.323913\n",
       "5 2023-11-18 19:02:03 -0.357332\n",
       "6 2023-11-22 19:06:27 -0.189824\n",
       "7 2023-11-23 19:22:30 -0.321991"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.DataFrame(values)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fcc17b",
   "metadata": {},
   "source": [
    "After gathering all the results and charting the output, we can see the acual collection times all fall somewhere between 18:00 - 19:30 UTC, or 10:00am - 11:30am local (Pacific) time, based on the example bounding box used when retrieving these values. When you run through this notebook with your own data, expect different UTC times but similar local times, based on the timezone of the data you are examining."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
