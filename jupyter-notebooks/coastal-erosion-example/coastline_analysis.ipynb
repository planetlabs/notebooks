{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coastline Recession in Bangladesh: A Temporal Analysis\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/planetlabs/notebooks/blob/master/jupyter-notebooks/coastal-erosion-example/coastline_analysis.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will be analyzing a severe example of coastal erosion. To do so we will:\n",
    "- Extract data from multi-band imagery\n",
    "- Compute the normalized difference water index (NDWI)\n",
    "- Use NDWI to identify which pixels are associated to water and which pixels are associated with land\n",
    "- Use classical image processing and computer vision techniques to analyze coastal erosion within the area of interest (AOI)\n",
    "\n",
    "We have provided you with data for your AOI, which has already been processed, mosaiced, and hosted.\n",
    "\n",
    "This AOI and analysis has been inspired by a the following paper: Crawford, T.W. et al., Coastal Erosion and Human Perceptions of Revetment Protection in the Lower Meghna Estuary of Bangladesh. Remote Sens. 2020, 12, 3108. https://doi.org/10.3390/rs12183108\n",
    "\n",
    "**For this tutorial, you will need to:**\n",
    "- Download all of the data needed for this analysis. If you're running this in Colab, then the data will be easily accessed by running the first code cell. Otherwise, please download these data from the following link: \n",
    "https://github.com/planetlabs/notebooks/blob/master/jupyter-notebooks/coastal-erosion-example/0_download_data.ipynb\n",
    "- Install and import the packages below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q -O tmp.zip https://hello.planet.com/data/s/HBBK6R2CRqLBQeC/download/coastal_erosion_workshop_data.zip && unzip tmp.zip && rm tmp.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve data\n",
    "Within our data folder, labeled `coastal_erosion_workshop_data`, we have both Analytic Surface Reflectance images and Visual images. While these images reflect the same AOI, they are used for different purposes. The visual images are colour-corrected and intended to be viewed and analyzed by the human eye, while the analytical images are orthorectified, radiometrically-calibrated, and are stored as 16-bit scaled radiance, which are intended to be used for scientific purposes. You may find out more on our [Dev Center](https://developers.planet.com/docs/data/planetscope/#asset-types).\n",
    "\n",
    "Let's retrieve both the multi-band and visual-band images across our entire time of interest (2017 - 2023), then sort the data to be chronological.\n",
    "\n",
    "The AOI encapsulates a small, 7 km (4.4 mi) long, coastal region in Kamalnagar, Chittagong, Bangladesh, which is located in Southern Bangladesh, where the ocean (Bay of Bengal) meets a major inlet, the Meghna River. We have chosen to image the AOI once each spring to analyze.\n",
    "\n",
    "Coastal erosion in Bangladesh is a recurring problem, causing thousands of people to be displaced annually. In fact, coastal Bangladesh experiences erosion rates that are among the highest in the world.\n",
    "\n",
    "<img src=\"assets/region.png\" height=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the analytic and visual data!\n",
    " \n",
    "Please note that this method below only works for Linux and Unix operating systems (i.e., Ubuntu, MacOS, etc.), however if you're running this on Colab, this will work just fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The base directory which holds all of the imagery\n",
    "data_directory = \"coastal_erosion_workshop_data\"\n",
    "\n",
    "# Find all relevant files\n",
    "analytic_filenames = glob(data_directory + \"/*analytic/composite.tif\")\n",
    "visual_filenames = glob(data_directory + \"/*visual/composite.tif\")\n",
    "\n",
    "# Sort the file chronologically, from 2017 to 2023\n",
    "analytic_filenames.sort()\n",
    "visual_filenames.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to create an image processing pipeline! For simplicity, we will wrap each method into individual functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract spectral bands\n",
    "Create a function to extract spectral bands from a PlanetScope 4-band imagery.\n",
    "These spectral bands will be used later to compute the normalized difference water index (NDWI), which will be used to find which pixels are associated with water and which are associated with land."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spectral_bands(image_filename):\n",
    "    \"\"\"\n",
    "    Extracts green and NIR bands from a PlanetScope 4-band imagery.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        image_filename : str\n",
    "                     The path to a PlanetScope 4-Band image.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "        green : Array[int]\n",
    "                     Green band image.\n",
    "        nir :   Array[int]\n",
    "                     NIR band image.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the green and NIR bands\n",
    "    with rasterio.open(image_filename) as src:\n",
    "        green = src.read(2)\n",
    "        nir = src.read(4)\n",
    "\n",
    "    return green, nir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how this function works for the last data point in our time series, in 2023. Since we've sorted our analytic and visual filenames, the 2023 image will be the second image (n = -1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's take our 2023 data as an example (last image in our dataset)\n",
    "n = -1\n",
    "# Extract the green and NIR bands from 2023's 4-band analytic image\n",
    "green, nir = extract_spectral_bands(analytic_filenames[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the green band using a non-default colour map & a colour bar\n",
    "# see also: https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
    "fig = plt.imshow(green)\n",
    "fig.set_cmap('gist_earth')\n",
    "plt.colorbar()\n",
    "plt.title(\"Green Band\")\n",
    "\n",
    "# Display the results.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the red band\n",
    "fig = plt.imshow(nir)\n",
    "fig.set_cmap('inferno')\n",
    "plt.colorbar()\n",
    "plt.title(\"NIR Band\")\n",
    "\n",
    "# Since the axis labels are useless here, let's turn them off.\n",
    "plt.axis('off')\n",
    "\n",
    "# Display the results.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compose scene using visual imagery\n",
    "Create a function to compose a scene, given red, green, and blue bands from PlanetScope Visual products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_scene(image_filename):\n",
    "    \"\"\"\n",
    "    Extracts red, green, and blue bands from a PlanetScope Visual product and\n",
    "    stacks them to compose a scene.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        image_filename : str\n",
    "                     The path to a PlanetScope 4-Band image.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "        red :   Array[int]\n",
    "                     Red band image.\n",
    "        green : Array[int]\n",
    "                     Green band image.\n",
    "        blue :  Array[int]\n",
    "                     Blue band image.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract visual imagery\n",
    "    with rasterio.open(image_filename) as src:\n",
    "        blue = src.read(1)\n",
    "        green = src.read(2)\n",
    "        red = src.read(3)\n",
    "\n",
    "    # Stack the 3 bands to create an RGB visual image\n",
    "    visual_image = np.dstack((blue, green, red))\n",
    "\n",
    "    return visual_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the AOI looks like with Visual product imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract visual images\n",
    "visual_image = compose_scene(visual_filenames[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(visual_image)\n",
    "plt.axis('off')\n",
    "plt.title(\"2023 visual image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Normalized Difference Water Index (NDWI)\n",
    "This function will measure the\n",
    "[normalized difference water index](https://en.wikipedia.org/wiki/Normalized_difference_water_index) (NDWI), \n",
    "defined as: $NDWI = (green - NIR) / (green + NIR)$.\n",
    "\n",
    "Please note that this requires that both the green and NIR imagery are normalized, which has already been done in the data processing pipeline for the Analytic Surface Reflectance data we're using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_ndwi(green, nir):\n",
    "    \"\"\"\n",
    "    Computes the normalized difference water index (NDWI).\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        green : Array[int]\n",
    "               Normalized green band image.\n",
    "        nir : Array[int]\n",
    "               Normalized NIR band image.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "        ndwi : Array[float]\n",
    "               Normalized difference water index.    \n",
    "    \"\"\"\n",
    "\n",
    "    # Allow division by zero\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "    # Calculate NDWI\n",
    "    ndwi = (green.astype(float) - nir.astype(float)) / (green + nir)\n",
    "\n",
    "    return ndwi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use our analytic imagery to compute the NDWI, which will help us determine which pixels are associated with water and which are associated with land."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute NDWI\n",
    "ndwi = measure_ndwi(green, nir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.imshow(ndwi)\n",
    "fig.set_cmap('Blues')\n",
    "plt.axis('off')\n",
    "plt.colorbar()\n",
    "plt.title(\"2023 NDWI Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the strip of coastline on the right side of the AOI has relatively low NDWI values and the water on the left has relatively high NDWI values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find water and land pixels\n",
    "NDWI values range from -1 to +1. Pixels which have a relatively high NDWI value (NDWI >= 0.3) are likely to be\n",
    "associated with water, whereas pixels with values under this threshold \n",
    "(NDWI < 0.3) are unlikely to be associated with water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_water_and_land(ndwi):\n",
    "    \"\"\"\n",
    "    Given an NDWI image, return a mask with pixels associated with water and\n",
    "    another mask with pixels associated with land.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        ndwi : Array[float]\n",
    "               Normalized difference water index.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "        water_mask : Array[int]\n",
    "               A binary mask for water.\n",
    "        land_mask :  Array[int]\n",
    "               A binary mask for land.\n",
    "    \"\"\"\n",
    "\n",
    "    # Although the water threshold is NDWI >= 0.3\n",
    "    # we'll set it lower to account of murky waters\n",
    "    WATER_THRESHOLD = 0.0\n",
    "\n",
    "    # Create arrays of NANs\n",
    "    water_mask = np.full(ndwi.shape, np.nan)\n",
    "    land_mask = np.full(ndwi.shape, np.nan)\n",
    "\n",
    "    # Threshold the NDWI image and create water & land masks\n",
    "    water_mask[ndwi >= WATER_THRESHOLD] = 1\n",
    "    land_mask[ndwi < WATER_THRESHOLD] = 1\n",
    "\n",
    "    return water_mask, land_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at the masks we created. Our `find_water_and_land()` function returns two arrays, `water_mask` and `land_mask`, both only containing 0s and 1s, where 1s indicate a positive association and 0s indicate a negative association. For instance, in the `water_mask` array, all pixels that have a value of 1 are associated with water and all pixels with a value of 0 are not. Let's take a moment to visualize our land mask as a `numpy` array. Note: NANs represent regions of the maps that have been clipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create water and land masks from the NDWI array\n",
    "water_mask, land_mask = find_water_and_land(ndwi)\n",
    "print(land_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize these water and land mask arrays as maps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.imshow(water_mask)\n",
    "plt.axis('off')\n",
    "plt.title(\"2023 water mask\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(1)\n",
    "plt.imshow(land_mask)\n",
    "plt.axis('off')\n",
    "plt.title(\"2023 land mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These masks correlate quite closely with where water and land actually exist, however notice how we see holes in the water and land masks? In the water mask, it is likely due to the fact that we are imaging especially murky water with either excessive vegetation growth, or perhaps these pixels are associated with sandbars off of the coast! For the land mask, we are likely picking up small bodies of water inland.\n",
    " \n",
    "For our coastline analysis, we only care about where the water meets the land, so it would be most helpful for us to have clean distinctions between what is \"mostly land\" to what is \"mostly waterâ€. Specifically, we want to create a mask for the ocean and a mask for the land. We can do this by applying morphological filters to clean up our pixel classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Filters\n",
    "We can apply [morphological filters](https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html)\n",
    "to filter out the unwanted pixels in the water and land masks.\n",
    "We use a closing filter to close small clusters of pixels (e.g., holes) inside parts of a mask.\n",
    "Following, we use an opening filter to remove any small clusters of pixels outside a mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_mask(closing_kernel_size, opening_kernel_size, mask):\n",
    "    \"\"\"\n",
    "    Given a mask, apply morphological filters (closing followed by opening) \n",
    "    to filter out unwanted pixels.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "       closing_kernel_size : Int\n",
    "                             Size of the closing kernel in pixels.\n",
    "       opening_kernel_size : Int\n",
    "                             Size of the opening kernel in pixels.\n",
    "        mask : Array[int]\n",
    "               A binary mask.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "        mask_closed_opened : Array[int]\n",
    "               A morphologically filtered binary mask.\n",
    "    \"\"\"\n",
    "\n",
    "    ## Closing filter: Remove empty pixels within mask\n",
    "    # Create a kernel element which is closing_kernel_size^2 in size\n",
    "    closing_kernel_element = (closing_kernel_size, closing_kernel_size)\n",
    "    # Create a closing filter kernel\n",
    "    closing_kernel = cv2.getStructuringElement(cv2.MORPH_RECT,\n",
    "                                               closing_kernel_element)\n",
    "    # Apply closing filter to input mask\n",
    "    mask_closed = cv2.morphologyEx(np.nan_to_num(mask), cv2.MORPH_CLOSE,\n",
    "                                   closing_kernel)\n",
    "\n",
    "    ## Opening filter: Removing filled pixels outside of mask\n",
    "    # Create a kernel element which is closing_kernel_size^2 in size\n",
    "    opening_kernel_element = (opening_kernel_size, opening_kernel_size)\n",
    "    # Create an opening filter kernel\n",
    "    opening_kernel = cv2.getStructuringElement(cv2.MORPH_RECT,\n",
    "                                               opening_kernel_element)\n",
    "    # Apply opening filter to closed mask\n",
    "    mask_closed_opened = cv2.morphologyEx(mask_closed, cv2.MORPH_OPEN,\n",
    "                                          opening_kernel)\n",
    "\n",
    "    # Ensure the clipped areas remain clipped\n",
    "    mask_closed_opened[mask_closed_opened == 0] = np.nan\n",
    "\n",
    "    return mask_closed_opened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this works in practice. Let's apply these morphological filters to both the water and land masks. These kernel sizes were chosen by empirical observations. To put them in physical units, multiply them by the pixel size (~3.7m / px)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the water mask\n",
    "CLOSING_KERNEL_SIZE = 29\n",
    "OPENING_KERNEL_SIZE = 13\n",
    "water_mask_filtered = filter_mask(CLOSING_KERNEL_SIZE, OPENING_KERNEL_SIZE,\n",
    "                                  water_mask)\n",
    "\n",
    "# Filter the land mask\n",
    "CLOSING_KERNEL_SIZE = 3\n",
    "OPENING_KERNEL_SIZE = 101\n",
    "land_mask_filtered = filter_mask(CLOSING_KERNEL_SIZE, OPENING_KERNEL_SIZE,\n",
    "                                 land_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.imshow(water_mask_filtered)\n",
    "plt.axis('off')\n",
    "plt.title(\"2023 filtered water mask\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(1)\n",
    "plt.imshow(land_mask_filtered)\n",
    "plt.axis('off')\n",
    "plt.title(\"2023 filtered land mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viola! Now we have clear distinctions between land and water without any pesky pixels to distract us!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can implement this entire process we just walked through, to each of the images over the time series, from 2017 to 2023.\n",
    " \n",
    "Below we've created an image processing pipeline, which will loop through each of the functions we created above, which will extract processed water and land masks for each date in our time series, from 2017 to 2023. At the end of the loop we store the filtered land mask in a list for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of years in the time series\n",
    "NUM_YEARS = 2023 - 2017 + 1\n",
    "# Create an empty list to append data\n",
    "all_land_masks = []\n",
    "\n",
    "# Process data for each year\n",
    "for n in range(NUM_YEARS):\n",
    "    # Extract green, red, and NIR data from 4-Band imagery\n",
    "    green, nir = extract_spectral_bands(analytic_filenames[n])\n",
    "    # Extract visual images\n",
    "    visual_image = compose_scene(visual_filenames[n])\n",
    "    # Compute NDWI\n",
    "    ndwi = measure_ndwi(green, nir)\n",
    "    # Create water and land masks\n",
    "    water_mask, land_mask = find_water_and_land(ndwi)\n",
    "    # Filter masks to fill out space\n",
    "    water_mask_filtered = filter_mask(29, 13, water_mask)\n",
    "    land_mask_filtered = filter_mask(3, 101, land_mask)\n",
    "    # Append land mask to a list for further analysis\n",
    "    all_land_masks.append(land_mask_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our NDWI thresholds and water and land masks for each date in our time series, we can begin interpreting the year-over-year changes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first look at landmass lost by measuring the physical area of land lost over time. To do this, first we'll simply take the difference between the land mask for the last image (2023) and the first image (2017), which will leave us with a new mask, which shows all land lost in our time series. Then, we'll count the number of pixels remaining, then multiply the number of pixels by the area of each pixel, which is 3.7m x 3.7m = 13.7 meters squared. For more information on PlanetScope resolution, check out our [Dev Center](https://developers.planet.com/docs/data/planetscope/)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Landmass Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The difference between the 2017 and the 2023 land masks\n",
    "# Using nan_to_num function to set all NANs to zero, as to not blow up the code\n",
    "land_difference = np.nan_to_num(all_land_masks[0]) - np.nan_to_num(\n",
    "    all_land_masks[-1])\n",
    "\n",
    "# resolution in m\n",
    "resolution = 3.7\n",
    "# area per pixel in m^2\n",
    "area_per_pixel = resolution**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Total landmass lost: {round(np.nansum(land_difference) * area_per_pixel * 1e-6)} km^2 over the past {NUM_YEARS} years\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the total landmass lost over our time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Landmass Lost\n",
    "plt.imshow(land_difference)\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.title(\"Cumulative landmass lost from 2017 to 2023\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute and visualize the amount of land lost over the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A time array for the time series\n",
    "time = np.arange(NUM_YEARS)\n",
    "\n",
    "# Compute the difference between the landmass of 2017 to each year\n",
    "landmass_loss = np.nansum(all_land_masks[0]) - list(\n",
    "    map(np.nansum, all_land_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative Landmass Lost\n",
    "plt.plot(time, landmass_loss * 1e-3, 'o-')\n",
    "plt.title(f\"Total Landmass lost over {NUM_YEARS} years\")\n",
    "plt.xlabel(\"Years since 2017\")\n",
    "plt.ylabel(r\"Area lost (1000 m$^2$)\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The landmass lost over the past 7 years is increasing rather quickly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how quickly is the coastal region losing land? Let's compute the velocity of landmass lost by measuring the change of land mass over the change of time, i.e. $v(t) = \\Delta M / \\Delta t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the velocity of landmass lost\n",
    "landmass_loss_velocity = np.diff(landmass_loss) / np.diff(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Velocity of Landmass Lost\n",
    "plt.plot(time[1:], landmass_loss_velocity * 1e-3, 'o-')\n",
    "plt.title(f\"Landmass lost over {NUM_YEARS} years is speeding up\")\n",
    "plt.xlabel(\"Years since 2017\")\n",
    "plt.ylabel(r\"Speed of area lost per year (1000 m$^2$ / yr)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The landmass lost doesn't appear to be happening at a constant rate - it appears to be speeding up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out how quickly the speed of landmass lost is speeding up by measuring its acceleration, i.e. $a(t) = \\Delta v / \\Delta t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the acceleration of landmass lost\n",
    "landmass_loss_acceleration = np.diff(landmass_loss_velocity) / np.diff(\n",
    "    time[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that our landmass loss over the past 6 years is accelerating\n",
    "plt.plot(time[2:], landmass_loss_acceleration * 1e-3, 'o-')\n",
    "plt.title(f\"Rate of landmass lost over {NUM_YEARS} years is accelerating\")\n",
    "plt.xlabel(\"Years since 2017\")\n",
    "plt.ylabel(r\"Acceleration of area lost per year (1000 m$^2$ / yr$^2$)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The speed at which this area is losing landmass is accelerating year after year, which means the problem is getting worse!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Land Recession"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going one step further, we can measure coastline erosion through land recession, in other words, we can measure how much the coastline has receded inland. One way to do this is to find the coastline in 2017 and 2023, then measure the distance between the two coasts. We can do this by looking at the `land_difference` array and using an edge detection algorithm to find the coastlines in 2017 and in 2023.\n",
    " \n",
    "Specifically, we'll employ a computer vision algorithm called \"Canny Edge Detection\" to detect the edge of the landmass at the beginning and end of our time series, then measure the distance between the two coasts.\n",
    " \n",
    "You can learn more about edge detection method we are using here: https://learnopencv.com/edge-detection-using-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect the edges of the cumulative land loss map\n",
    "edges_all = cv2.Canny(image=np.uint8(land_difference),\n",
    "                      threshold1=0,\n",
    "                      threshold2=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure below shows the canny edge detection's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(edges_all, vmin=0, vmax=1)\n",
    "plt.axis('off')\n",
    "plt.title(\"Canny Edge Detection\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can create an automated search for the 2017 coastline (on the left) and the 2023 coastline (on the right). We'll do this by creating a histogram of all of the coastal pixels, by binning up all of the pixels from left to right, vertically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin up all edge pixels, vertically\n",
    "_, xpos = np.where(edges_all > 0)\n",
    "NUM_BINS = 12\n",
    "N, x = np.histogram(xpos, bins=NUM_BINS)\n",
    "bin_width = x[1] - x[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can identify the peaks of the histogram and use those to roughly identify where the 2017 and 2023 coastlines are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the peaks of the histogram -> these are the coastline edges\n",
    "coastlines = x[find_peaks(N)[0]]\n",
    "coastline_2017 = coastlines[0]\n",
    "coastline_2023 = coastlines[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly visualize the resulting histogram and the associated peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(xpos, bins=NUM_BINS, alpha=0.5)\n",
    "plt.axvline(x=coastline_2017 + bin_width / 2, color='k', ls='--')\n",
    "plt.axvline(x=coastline_2023 + bin_width / 2, color='k', ls='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the output from the canny edge detection with the histogram overlaid and with its peaks identified with black dashed lines. These peaks very closely correlate to where the coastlines actually exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(edges_all, vmin=0, vmax=1)\n",
    "plt.hist(xpos, bins=NUM_BINS, alpha=0.5)\n",
    "plt.axvline(x=coastline_2017 + bin_width / 2, color='k', ls='--')\n",
    "plt.axvline(x=coastline_2023 + bin_width / 2, color='k', ls='--')\n",
    "plt.title(\"Canny Edge Detection (used for coast line detection)\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a rough estimate as to where our 2017 and 2023 coasts reside! However, we should note that this method only works if the coasts are vertically-aligned to the frame of reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's compute how much the coast has receded inland by taking the difference between the two coastline positions and multiplying them by the number of meters per pixels (~3.7 m/px)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recession = (coastline_2023 - coastline_2017) * resolution\n",
    "\n",
    "print(f\"Land has receded {round(recession)} meters in {NUM_YEARS} years\")\n",
    "print(\n",
    "    f\"Land has receded {round(recession / NUM_YEARS)} meters/yr over the past {NUM_YEARS} years\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "169c2a6d6f6b3b6f3764016389a0a1d9dfa7d18d4ccd8b215971315354c20651"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
